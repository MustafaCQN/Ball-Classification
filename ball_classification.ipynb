{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWzMm7-Tnm-f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_path=\"/content/drive/MyDrive/BallData/train\"\n",
        "data_test_path=\"/content/drive/MyDrive/BallData/test\"\n",
        "\n",
        "batch_size=4\n",
        "img_size=224\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001,decay = 1e-4)\n",
        "loss=\"categorical_crossentropy\"\n",
        "epochs=10\n",
        "onnx_path=\"/content/drive/MyDrive/BallOnnxModel/model.onnx\"\n"
      ],
      "metadata": {
        "id": "2LFR-Jr3n78U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator_test = ImageDataGenerator(rescale=1./255,)    \n",
        "data_train = image_generator_test.flow_from_directory(batch_size=batch_size,\n",
        "                                                  directory=data_train_path,\n",
        "                                                  shuffle=True,\n",
        "                                                  target_size=(img_size, img_size), \n",
        "                                                  class_mode='categorical'\n",
        "  \n",
        "                                                  )\n",
        "data_test = image_generator_test.flow_from_directory(batch_size=batch_size,\n",
        "                                                  directory=data_test_path,\n",
        "                                                  shuffle=True,\n",
        "                                                  target_size=(img_size, img_size), \n",
        "                                                  class_mode='categorical'\n",
        "  \n",
        "                                                  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWqpNVVgn9cx",
        "outputId": "c72ba1f1-62ee-4044-dcb9-fc95ad81e114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 172 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Data\",data_train.class_indices)\n",
        "print(\"Test Data\",data_test.class_indices)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx_MFkm2n-mI",
        "outputId": "833290e4-f9c2-4ea7-8bdd-76e69b6d4203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data {'colored_beachball': 0, 'football': 1}\n",
            "Test Data {'colored_beachball': 0, 'football': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization,concatenate,Conv2DTranspose,Dropout\n",
        "\n",
        "inputs=Input(shape=(224,224,3),name=\"input\")\n",
        "    \n",
        "x = Conv2D(16,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(32,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(64,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(128,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(256,(3,3),activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "\n",
        "x=tf.keras.layers.GlobalMaxPool2D()(x)\n",
        "\n",
        "x=tf.keras.layers.Dense(128,activation=\"relu\")(x)\n",
        "x=tf.keras.layers.Dense(len(data_train.class_indices),activation=\"softmax\",name=\"output\")(x)\n",
        "\n",
        "model=tf.keras.Model(inputs=inputs,outputs=x)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer =optimizer,loss = loss,  metrics = [\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBuqD4Spn_nM",
        "outputId": "366f1818-5051-4684-cf78-c9dbfb822950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 112, 112, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 112, 112, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 56, 56, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 28, 28, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 14, 14, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " global_max_pooling2d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " output (Dense)              (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 425,762\n",
            "Trainable params: 425,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[]\n",
        "callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',factor = 0.1,patience = 2,min=1e-6,verbose=1))\n",
        "callbacks.append(tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=4,restore_best_weights=True))"
      ],
      "metadata": {
        "id": "6d7R05iDoAxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(data_train,validation_data=data_test,  epochs = 10,callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "NTZ0PuscoBtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "img = Image.open(\"/content/drive/MyDrive/BallData/test/football/football22.png\").convert('RGB').resize((img_size,img_size))\n",
        "img=np.asarray(img)\n",
        "predicted=model.predict(np.expand_dims(img,axis=0))\n",
        "predicted\n",
        "list(data_train.class_indices.keys())[np.argmax(predicted)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "dvWf7TkGoCzg",
        "outputId": "1a1e4d6d-9f7c-4a58-8073-d9954d1e0961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'football'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXmJWS2LpK1n",
        "outputId": "6d4ac66e-080b-4319-c00f-1fda69b2daed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_model_path=\"/content/saved_model\"\n",
        "if not os.path.isdir(save_model_path):\n",
        "      os.makedirs(save_model_path)\n",
        "\n",
        "model.save(save_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0smWc1r-oD1E",
        "outputId": "fb0d50e2-9a0a-43f5-d5b8-42a1bf2e0ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx\n",
        "!pip install -U tf2onnx\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Gnb5iPoE9O",
        "outputId": "5667a37c-68bd-4667-abbb-c81ff4020912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.13.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (21.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime) (3.19.6)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime) (1.2.1)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.13.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx) (1.21.6)\n",
            "Installing collected packages: protobuf, onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnx-1.13.0 protobuf-3.20.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (2.25.1)\n",
            "Requirement already satisfied: onnx>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Installing collected packages: tf2onnx\n",
            "Successfully installed tf2onnx-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m tf2onnx.convert --saved-model /content/saved_model --opset 9 --output {onnx_path}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S38ot5lUpEhb",
        "outputId": "9c728eef-981b-44b3-ba0a-0f7c86057e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "2023-02-01 11:36:20,900 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
            "2023-02-01 11:36:21,234 - INFO - Signatures found in model: [serving_default].\n",
            "2023-02-01 11:36:21,234 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
            "2023-02-01 11:36:21,234 - INFO - Output names: ['output']\n",
            "2023-02-01 11:36:21,355 - INFO - Using tensorflow=2.9.2, onnx=1.13.0, tf2onnx=1.13.0/2c1db5\n",
            "2023-02-01 11:36:21,355 - INFO - Using opset <onnx, 9>\n",
            "2023-02-01 11:36:21,454 - INFO - Computed 0 values for constant folding\n",
            "2023-02-01 11:36:21,536 - INFO - Optimizing ONNX model\n",
            "2023-02-01 11:36:21,605 - INFO - After optimization: Const -1 (15->14), GlobalMaxPool +1 (0->1), Identity -2 (2->0), ReduceMax -1 (1->0), Squeeze +1 (0->1), Transpose -17 (18->1)\n",
            "2023-02-01 11:36:21,616 - INFO - \n",
            "2023-02-01 11:36:21,616 - INFO - Successfully converted TensorFlow model /content/saved_model to ONNX\n",
            "2023-02-01 11:36:21,616 - INFO - Model inputs: ['input']\n",
            "2023-02-01 11:36:21,616 - INFO - Model outputs: ['output']\n",
            "2023-02-01 11:36:21,616 - INFO - ONNX model is saved at /content/drive/MyDrive/BallOnnxModel/model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "img = Image.open(\"/content/WhatsApp Image 2023-02-01 at 14.12.18 (1).jpeg\").convert('RGB').resize((224,224))\n",
        "img=np.expand_dims(np.asarray(img, dtype=\"float32\"),axis=0)\n",
        "img=img/255\n",
        "\n",
        "sess_ort = ort.InferenceSession(onnx_path,providers=ort.get_available_providers())\n",
        "\n",
        "outputs = sess_ort.run(None, {sess_ort.get_inputs()[0].name: img})\n",
        "print(outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P4ohgnTuBk1",
        "outputId": "5ec1f2ce-4c83-4ef6-87e9-02dd12425e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0.9725016 , 0.02749839]], dtype=float32)]\n"
          ]
        }
      ]
    }
  ]
}